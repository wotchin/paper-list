# 介绍
此处介绍经典的深度学习理论论文，仅涉及通用深度学习部分，细分领域参见其他部分。

# Paper List
|Name|Comment|Published Year|
|-|-|-|
|Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift|批归一化方法，能够显著提升模型性能。|2015|
|Improving neural networks by preventing co-adaptation of feature detectors|Hinton首次提出Dropout，能够防止过拟合，提高训练模型的泛化能力。|2012|
|Dropout: A Simple Way to Prevent Neural Networks from Overfitting|Dropout补充|2014|
|Improving Neural Network Generalization by Combining Parallel Circuits with Dropout|Dropout补充|2016|
|Dropout as data augmentation|Dropout补充|2015|
|Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)|ELU激活函数|2015|
|Self-Normalizing Neural Networks|提出SELUs激活函数，在FNN中表现优异|2017|
